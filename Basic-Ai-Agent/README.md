# ğŸš€ My First AI Agent Using `openai-agent-sdk` + Gemini API ğŸŒŸ

This project marks my first successful attempt at creating an AI agent using the `openai-agent-sdk` and integrating it with **Google Gemini API** via OpenAI-compatible endpoints. Here's a breakdown of the code and its functionality:

---

## ğŸ“¦ Importing Required Libraries

```
python
import asyncio
import os
from dotenv import load_dotenv
from openai import AsyncOpenAI
from agents import Agent, OpenAIChatCompletionsModel, Runner, set_tracing_disabled
```


- ğŸ”„ `asyncio`: Enables asynchronous execution.
- ğŸ” `os` & ğŸŒ¿ `dotenv`: Load environment variables securely.
- ğŸ¤– `AsyncOpenAI`: Client for OpenAI-compatible APIs.
- ğŸ§  `agents`: Core SDK components to define and run the AI agent.


---


## ğŸ” Loading the Gemini API Key


```
python\nload_dotenv()
gemini_api_key = os.getenv("gemini_api_key")
```


- ğŸ—ï¸ Loads your Gemini API key from a `.env` file to keep it secure and hidden.


---


## ğŸŒ Setting Up the Gemini Client


```
client = AsyncOpenAI(
    api_key=gemini_api_key,
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
)
```
            
            
- ğŸ”Œ Connects to Gemini using OpenAI-compatible endpoints.
- ğŸ§  Enables use of Gemini models like `gemini-2.0-flash`.


---


## ğŸ›‘ Disabling Tracing (Optional)


```
python
set_tracing_disabled(disabled=True)
```


- ğŸ§­ Turns off internal tracing/logging for cleaner output.


---


## ğŸ§  Creating the AI Agent


```
     agent = Agent(
    name="Assistant",
    instructions="You are a helpful assistant .",
    model=OpenAIChatCompletionsModel(model="gemini-2.0-flash", openai_client=client),
)       
```
        
        
        
- ğŸ§‘â€ğŸ’¼ Defines the agent named **Assistant**.
- ğŸ“œ Provides behavior instructions.
- âš™ï¸ Uses Gemini model via OpenAI-compatible client.

---

## ğŸ’¬ Running the Agent with User Input

```
userInput = input("inter your prompt: ")
result = await Runner.run(
    agent,
    userInput,
)
print(result.final_output)
```

- ğŸ§‘â€ğŸ’» Accepts user prompt.
- ğŸƒâ€â™‚ï¸ Executes the agent using `Runner.run()`.
- ğŸ“¢ Displays the final output.

---

## ğŸ§ª Executing the Main Function

```
if __name__ == "__main__":
    asyncio.run(main())
```


- ğŸš€ Launches the asynchronous main function when the script is run.


---

## ğŸ“Š Summary Table

| ğŸ”§ Component       | ğŸ’¡ Description                                 |
|-------------------|------------------------------------------------|
| ğŸ¤– Agent Name      | `Assistant`                                    |
| ğŸ§  Model Used      | `gemini-2.0-flash`                              |
| ğŸ”— API Type        | OpenAI-compatible Gemini endpoint              |
| ğŸ› ï¸ SDK             | `openai-agent-sdk`                             |
| ğŸ§ª Execution       | Asynchronous with `asyncio`                    |

---

## ğŸ‰ Final Thoughts\n\nThis is a major milestone in my AI journey!  
Iâ€™ve successfully built an agent that:
- âœ… Uses Gemini via OpenAI-compatible endpoints
- âœ… Responds to user prompts
- âœ… Runs asynchronously
- âœ… Is ready for future enhancements

---

Would you like to add memory, tools, or a web interface next? ğŸ˜  
Letâ€™s keep building! ğŸ’»âœ¨